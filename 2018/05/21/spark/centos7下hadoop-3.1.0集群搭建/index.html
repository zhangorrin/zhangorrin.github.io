<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>centos7下hadoop-3.1.0集群搭建 | 粗茶淡饭</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="环境准备1.服务器概览    hostname ip 说明     node1.spark 192.168.2.140 node1节点(master)   node2.spark 192.168.2.141 node2节点   node3.spark 192.168.2.142 node3节点    分别在三台服务器上执行以下命令 123456789101112131415161718#添加hos">
<meta name="keywords" content="程序员，架构师">
<meta property="og:type" content="article">
<meta property="og:title" content="centos7下hadoop-3.1.0集群搭建">
<meta property="og:url" content="https://zhangorrin.github.io/2018/05/21/spark/centos7下hadoop-3.1.0集群搭建/index.html">
<meta property="og:site_name" content="粗茶淡饭">
<meta property="og:description" content="环境准备1.服务器概览    hostname ip 说明     node1.spark 192.168.2.140 node1节点(master)   node2.spark 192.168.2.141 node2节点   node3.spark 192.168.2.142 node3节点    分别在三台服务器上执行以下命令 123456789101112131415161718#添加hos">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2018-05-21T07:08:12.151Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="centos7下hadoop-3.1.0集群搭建">
<meta name="twitter:description" content="环境准备1.服务器概览    hostname ip 说明     node1.spark 192.168.2.140 node1节点(master)   node2.spark 192.168.2.141 node2节点   node3.spark 192.168.2.142 node3节点    分别在三台服务器上执行以下命令 123456789101112131415161718#添加hos">
  
    <link rel="alternate" href="/atom.xml" title="粗茶淡饭" type="application/atom+xml">
  
  
    <link rel="icon" href="/css/images/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">粗茶淡饭</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">积累，记录，与分享</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives/">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://zhangorrin.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-spark/centos7下hadoop-3.1.0集群搭建" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/05/21/spark/centos7下hadoop-3.1.0集群搭建/" class="article-date">
  <time datetime="2018-05-21T07:07:42.118Z" itemprop="datePublished">2018-05-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      centos7下hadoop-3.1.0集群搭建
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p><strong>1.服务器概览</strong></p>
<table>
<thead>
<tr>
<th>hostname</th>
<th>ip</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>node1.spark</td>
<td>192.168.2.140</td>
<td>node1节点(master)</td>
</tr>
<tr>
<td>node2.spark</td>
<td>192.168.2.141</td>
<td>node2节点</td>
</tr>
<tr>
<td>node3.spark</td>
<td>192.168.2.142</td>
<td>node3节点</td>
</tr>
</tbody>
</table>
<p>分别在三台服务器上执行以下命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">#添加host</span><br><span class="line">[root@node1 ~] vim /etc/hosts</span><br><span class="line">192.168.2.140 node1.spark</span><br><span class="line">192.168.2.141 node2.spark</span><br><span class="line">192.168.2.142 node3.spark</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#执行以下命令关闭防火墙</span><br><span class="line">[root@node1 ~]systemctl stop firewalld &amp;&amp; systemctl disable firewalld</span><br><span class="line">[root@node1 ~]setenforce 0</span><br><span class="line"></span><br><span class="line">#将SELINUX的值改成disabled</span><br><span class="line">[root@node1 ~]vim /etc/selinux/config</span><br><span class="line"></span><br><span class="line">SELINUX=disabled</span><br><span class="line"></span><br><span class="line">#重启服务器</span><br><span class="line">[root@node1 ~]reboot</span><br></pre></td></tr></table></figure>
<p><strong>2.配置免密码登录</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#node1执行以下命令</span><br><span class="line"></span><br><span class="line">#生成密钥Pair,输入之后一直选择enter即可。生成的秘钥位于 ~/.ssh文件夹下</span><br><span class="line">[root@node1 ~]# ssh-keygen -t rsa </span><br><span class="line"></span><br><span class="line">[root@node1 .ssh]# scp /root/.ssh/id_rsa.pub root@spark.node2:~</span><br><span class="line">[root@node1 .ssh]# scp /root/.ssh/id_rsa.pub root@spark.node3:~</span><br><span class="line"></span><br><span class="line">##node2,node3 执行以下命令</span><br><span class="line">[root@node2 ~]# mkdir -p ~/.ssh</span><br><span class="line">[root@node2 ~]# cd .ssh/</span><br><span class="line">[root@node2 .ssh]# cat ~/id_rsa.pub &gt;&gt; authorized_keys</span><br><span class="line">[root@node2 .ssh]# vim /etc/ssh/sshd_config</span><br><span class="line">#禁用root账户登录，如果是用root用户登录请开启</span><br><span class="line">PermitRootLogin yes</span><br></pre></td></tr></table></figure>
<p><strong>3.JDK安装</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#配置环境变量</span><br><span class="line">[root@node1 ~]# vim /etc/profile</span><br><span class="line"></span><br><span class="line"># 在最后下添加</span><br><span class="line"># Java Environment Path</span><br><span class="line">export JAVA_HOME=/opt/java/jdk1.8.0_172</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"></span><br><span class="line"># 刷新配置文件</span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
<h2 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h2><p><strong>1.安装Hadoop</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 opt]# cd /opt/ &amp; mkdir hadoop &amp;&amp; cd hadoop</span><br><span class="line">#解压hadoop-3.1.0.tar.gz</span><br><span class="line">[root@node1 hadoop]# tar -zxvf hadoop-3.1.0.tar.gz</span><br><span class="line"></span><br><span class="line">#修改环境变量</span><br><span class="line">[root@node1 hadoop]# vim /etc/profile</span><br><span class="line"></span><br><span class="line"># 在最后下添加</span><br><span class="line">export HADOOP_HOME=/opt/hadoop/hadoop-3.1.0</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 刷新配置文件</span><br><span class="line">[root@node1 hadoop]# source /etc/profile</span><br></pre></td></tr></table></figure></p>
<p><strong>2.修改配置文件</strong></p>
<blockquote>
<p>这些配置文件全部位于 /opt/hadoop/hadoop-3.1.0/etc/hadoop 文件夹下</p>
</blockquote>
<p>hadoop-env.sh<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#The java implementation to use. By default, this environment</span><br><span class="line"></span><br><span class="line"># variable is REQUIRED on ALL platforms except OS X!</span><br><span class="line"># export JAVA_HOME=</span><br><span class="line">export JAVA_HOME=/opt/java/jdk1.8.0_172</span><br></pre></td></tr></table></figure></p>
<p>core-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定HDFS老大（namenode）的通信地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://node1.spark:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定hadoop运行时产生文件的存储路径 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>hdfs-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 设置namenode的http通讯地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node1.spark:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 设置secondarynamenode的http通讯地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node2.spark:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 设置namenode存放的路径 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop/data/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 设置hdfs副本数量 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 设置datanode存放的路径 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop/data/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>mapred-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 通知框架MR使用YARN --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.application.classpath<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>  </span><br><span class="line">        /opt/hadoop/hadoop-3.1.0/etc/hadoop,  </span><br><span class="line">        /opt/hadoop/hadoop-3.1.0/share/hadoop/common/*,  </span><br><span class="line">        /opt/hadoop/hadoop-3.1.0/share/hadoop/common/lib/*,  </span><br><span class="line">        /opt/hadoop/hadoop-3.1.0/share/hadoop/hdfs/*,  </span><br><span class="line">        /opt/hadoop/hadoop-3.1.0/share/hadoop/hdfs/lib/*,  </span><br><span class="line">        /opt/hadoop/hadoop-3.1.0/share/hadoop/mapreduce/*,  </span><br><span class="line">        /opt/hadoop/hadoop-3.1.0/share/hadoop/mapreduce/lib/*,  </span><br><span class="line">        /opt/hadoop/hadoop-3.1.0/share/hadoop/yarn/*,  </span><br><span class="line">        /opt/hadoop/hadoop-3.1.0/share/hadoop/yarn/lib/*  </span><br><span class="line">        <span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>yarn-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandle<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node1.spark:8025<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node1.spark:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node1.spark:8040<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>sbin/start-dfs.sh sbin/stop-dfs.sh<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">HDFS_DATANODE_USER=root </span><br><span class="line">HADOOP_SECURE_DN_USER=hdfs </span><br><span class="line">HDFS_NAMENODE_USER=root </span><br><span class="line">HDFS_SECONDARYNAMENODE_USER=root</span><br></pre></td></tr></table></figure></p>
<p>sbin/start-yarn.sh sbin/stop-yarn.sh<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">HADOOP_SECURE_DN_USER=yarn </span><br><span class="line">YARN_NODEMANAGER_USER=root</span><br></pre></td></tr></table></figure></p>
<p>masters</p>
<blockquote>
<p>新建一个masters的文件,这里指定的是secondary namenode 的主机<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 hadoop]# touch /opt/hadoop/hadoop-3.1.0/etc/hadoop/masters</span><br><span class="line">[root@node1 hadoop]# vim /opt/hadoop/hadoop-3.1.0/etc/hadoop/masters</span><br><span class="line">#添加</span><br><span class="line">node2.spark</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>workers<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 hadoop]# touch /opt/hadoop/hadoop-3.1.0/etc/hadoop/slaves</span><br><span class="line">[root@node1 hadoop]# vim /opt/hadoop/hadoop-3.1.0/etc/hadoop/slaves</span><br><span class="line">#添加</span><br><span class="line">node2.spark</span><br><span class="line">node3.spark</span><br></pre></td></tr></table></figure></p>
<p>创建文件夹<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 hadoop]# mkdir -p /opt/hadoop/data/tmp</span><br><span class="line">[root@node1 hadoop]# mkdir -p /opt/hadoop/data/name</span><br><span class="line">[root@node1 hadoop]# mkdir -p /opt/hadoop/data/datanode</span><br></pre></td></tr></table></figure></p>
<p>复制到其他主机<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 opt]# scp -r /opt/hadoop spark.node2:/opt/</span><br><span class="line">[root@node1 opt]# scp -r /opt/hadoop spark.node3:/opt/</span><br></pre></td></tr></table></figure></p>
<p>修改spark.node2 spark.node3 环境变量<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#修改环境变量</span><br><span class="line">[root@node2 hadoop]# vim /etc/profile</span><br><span class="line"></span><br><span class="line"># 在最后下添加</span><br><span class="line">export HADOOP_HOME=/opt/hadoop/hadoop-3.1.0</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 刷新配置文件</span><br><span class="line">[root@node2 hadoop]# source /etc/profile</span><br></pre></td></tr></table></figure></p>
<p><strong>3.启动</strong><br>第一次启动得格式化<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 opt]#  /opt/hadoop/hadoop-3.1.0/bin/hdfs namenode -format</span><br></pre></td></tr></table></figure></p>
<p>启动<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 opt]#  /opt/hadoop/hadoop-3.1.0/sbin/start-all.sh</span><br></pre></td></tr></table></figure></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://zhangorrin.github.io/2018/05/21/spark/centos7下hadoop-3.1.0集群搭建/" data-id="cjhfww03f0001eozjxh7dvnz1" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2018/05/14/spark/windows10下spark本地开发环境搭建/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">windows10下spark本地开发环境搭建</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/05/21/spark/centos7下hadoop-3.1.0集群搭建/">centos7下hadoop-3.1.0集群搭建</a>
          </li>
        
          <li>
            <a href="/2018/05/14/spark/windows10下spark本地开发环境搭建/">windows10下spark本地开发环境搭建</a>
          </li>
        
          <li>
            <a href="/2018/05/10/hello-blog/">Hello Blog</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 ZhangOrrin<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives/" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>